{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1a32d4",
   "metadata": {},
   "source": [
    "# Saving and loading trained policies in JaxPlan. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df640593",
   "metadata": {},
   "source": [
    "In this notebook, we illustrate the procedure of saving and loading trained JaxPlan policies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29af0af",
   "metadata": {},
   "source": [
    "Start by installing the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca10951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade pip\n",
    "%pip install --quiet pyRDDLGym rddlrepository pyRDDLGym-jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee945c7",
   "metadata": {},
   "source": [
    "Import the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06501d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import pickle\n",
    "\n",
    "import pyRDDLGym\n",
    "from pyRDDLGym_jax.core.planner import JaxDeepReactivePolicy, JaxBackpropPlanner, JaxOfflineController, load_config_from_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9ed29c",
   "metadata": {},
   "source": [
    "We will load the Wildfire example to illustrate the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "750dff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = pyRDDLGym.make('Wildfire_MDP_ippc2014', '1', vectorized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c1b3a",
   "metadata": {},
   "source": [
    "Let's now train a fresh policy network to solve this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf99e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] JAX gradient compiler will cast p-vars {'burning', 'NEIGHBOR', \"out-of-fuel'\", 'cut-out', \"burning'\", 'out-of-fuel', 'put-out', 'TARGET'} to float.\u001b[0m\n",
      "\u001b[32m[INFO] JAX gradient compiler will cast CPFs {\"burning'\", \"out-of-fuel'\"} to float.\u001b[0m\n",
      "\u001b[32m[INFO] Bounds of action-fluent <put-out> set to (None, None).\u001b[0m\n",
      "\u001b[32m[INFO] Bounds of action-fluent <cut-out> set to (None, None).\u001b[0m\n",
      "\u001b[33m[WARN] policy_hyperparams is not set, setting 1.0 for all action-fluents which could be suboptimal.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0 it /    -6698.47021 train /    -4108.43750 test /    -4108.43750 best / 0 status /      0 pgpe:  11%| | 00:02 ,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[FAIL] Compiler encountered the following error(s) in the training model:\n",
      "    Casting occurred that could result in loss of precision.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   1769 it /    -2767.67480 train /     -768.50000 test /     -477.21875 best / 5 status /      0 pgpe: 100%|â–ˆ| 00:29 ,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean': np.float64(-615.4),\n",
       " 'median': np.float64(-210.0),\n",
       " 'min': np.float64(-8035.0),\n",
       " 'max': np.float64(-210.0),\n",
       " 'std': np.float64(1276.131983769704)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planner = JaxBackpropPlanner(rddl=env.model, plan=JaxDeepReactivePolicy(), pgpe=None, optimizer_kwargs={'learning_rate': 0.01})\n",
    "agent = JaxOfflineController(planner, print_summary=False, train_seconds=30)\n",
    "agent.evaluate(env, episodes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b72d9f2",
   "metadata": {},
   "source": [
    "To save the model, we will just pickle the final parameters of the policy network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e289af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wildfire_drp.pickle', 'wb') as file:\n",
    "    pickle.dump(agent.params, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49379b37",
   "metadata": {},
   "source": [
    "Now, let's load the pickled parameters and pass them to a newly-instantiated controller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5ba9d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] JAX gradient compiler will cast p-vars {'burning', 'NEIGHBOR', \"out-of-fuel'\", 'cut-out', \"burning'\", 'out-of-fuel', 'put-out', 'TARGET'} to float.\u001b[0m\n",
      "\u001b[32m[INFO] JAX gradient compiler will cast CPFs {\"burning'\", \"out-of-fuel'\"} to float.\u001b[0m\n",
      "\u001b[32m[INFO] Bounds of action-fluent <put-out> set to (None, None).\u001b[0m\n",
      "\u001b[32m[INFO] Bounds of action-fluent <cut-out> set to (None, None).\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with open('wildfire_drp.pickle', 'rb') as file:\n",
    "    params = pickle.load(file)    \n",
    "new_planner = JaxBackpropPlanner(rddl=env.model, plan=JaxDeepReactivePolicy())\n",
    "new_agent = JaxOfflineController(new_planner, params=params, print_summary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e308bf",
   "metadata": {},
   "source": [
    "Note that in this case there is no pre-training of the policy. Let's evaluate the agent to make sure it still performs the same as the trained one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c212dce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': np.float64(-523.8),\n",
       " 'median': np.float64(-210.0),\n",
       " 'min': np.float64(-8270.0),\n",
       " 'max': np.float64(-210.0),\n",
       " 'std': np.float64(1204.700402589789)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_agent.evaluate(env, episodes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709354d5",
   "metadata": {},
   "source": [
    "Indeed, the performance is quite similar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
